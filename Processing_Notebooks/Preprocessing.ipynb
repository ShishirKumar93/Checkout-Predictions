{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:49:04.027732Z",
     "start_time": "2020-01-16T05:48:59.296078Z"
    }
   },
   "source": [
    "## This notebook performs the initial filtering on our two main sources containing data on the \"Inventory\" and \"Checkout\" data for the Seattle Public Library data set. These two CSVs were originally over ~20 GB and were reduced to ~1 GB parquet files and published on S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:13.202669Z",
     "start_time": "2020-01-16T05:52:09.850210Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from itertools import islice\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import desc, col, udf, max as max_\n",
    "from pyspark.sql import SQLContext\n",
    "import re\n",
    "\n",
    "# Instantiate spark context and spark session\n",
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define schema and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:13.271683Z",
     "start_time": "2020-01-16T05:52:13.205442Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate spark context and spark session\n",
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define schemas\n",
    "inventory_schema = StructType([\n",
    "    StructField(\"BibNum\", IntegerType(), True),\n",
    "    StructField(\"PublicationYear\", IntegerType(), True),\n",
    "    StructField(\"Author\", StringType(), True),\n",
    "    StructField(\"Publisher\", StringType(), True),\n",
    "    StructField(\"ItemType\", StringType(), True),\n",
    "    StructField(\"ItemCollection\", StringType(), True),\n",
    "    StructField(\"ItemLocation\", StringType(), True),\n",
    "    StructField(\"ItemCount\", IntegerType(), True),\n",
    "    StructField(\"ReportDate\", DateType(), True)])\n",
    "\n",
    "checkout_schema = StructType([StructField(\"BibNumber\", IntegerType(), True),\n",
    "                              StructField(\"CheckoutDateTime\", DateType(), True)])\n",
    "\n",
    "# Define helper functions\n",
    "def tryInt(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except:\n",
    "        return \n",
    "    \n",
    "def itemCount(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def tryReplace(val):\n",
    "    try:\n",
    "        val = int(re.sub('\\D', '', val))\n",
    "        assert len(str(val)) == 4\n",
    "        return val\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def toTimeSafe(inval):\n",
    "    date = inval.split(' ')[0]\n",
    "    try:\n",
    "        return datetime.strptime(date, '%m/%d/%Y').date()\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def toTimeSafe2(date):\n",
    "    if date != None: \n",
    "        try:\n",
    "            return datetime.strptime(date, '%m/%d/%Y').date()\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inventory table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:16.451720Z",
     "start_time": "2020-01-16T05:52:13.274115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in df\n",
    "tmp_inventory_df = ss.read.csv('Library_Collection_Inventory.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:16.867295Z",
     "start_time": "2020-01-16T05:52:16.453784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generating function for MapPartitions\n",
    "def drop_collection(lst):\n",
    "    for x in lst:\n",
    "        yield (tryInt(x[0]), tryReplace(x[4]), x[2], x[5],\n",
    "               x[7], x[8], x[10], itemCount(x[-1]), toTimeSafe2(x[-2]))\n",
    "        \n",
    "# Convert dataframe to rdd and filter\n",
    "library_rdd = tmp_inventory_df.rdd.mapPartitions(drop_collection)\n",
    "\n",
    "# Convert back to final df\n",
    "inventory_df = ss.createDataFrame(library_rdd, schema=inventory_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create checkout table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:17.147976Z",
     "start_time": "2020-01-16T05:52:16.869143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in df\n",
    "tmp_checkout_df = ss.read.csv('checkouts_filt.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:17.228124Z",
     "start_time": "2020-01-16T05:52:17.150129Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert dataframe to rdd and filter\n",
    "checkout_rdd = tmp_checkout_df.rdd\n",
    "checkout_rdd = checkout_rdd.map(lambda x: (x[2],x[-1]))\n",
    "\n",
    "# Convert back to final df\n",
    "checkout = checkout_rdd.map(lambda x: (tryInt(x[0]), toTimeSafe(x[1])))\n",
    "checkout_df = ss.createDataFrame(checkout, checkout_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at both of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:18.369175Z",
     "start_time": "2020-01-16T05:52:17.230493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------------+--------+--------------+------------+---------+----------+\n",
      "| BibNum|PublicationYear|              Author|           Publisher|ItemType|ItemCollection|ItemLocation|ItemCount|ReportDate|\n",
      "+-------+---------------+--------------------+--------------------+--------+--------------+------------+---------+----------+\n",
      "|2731930|           2011|MacLachlan, Patricia|Atheneum Books fo...|    jcbk|         ncfic|         gwd|        1|2019-02-01|\n",
      "|2983336|           2014|O'Connell, Robert L.|       Random House,|    acbk|           nab|         bea|        1|2019-02-01|\n",
      "|3343596|           2013|                null|      Kino Classics,|   acdvd|         nadvd|         qna|        1|2019-02-01|\n",
      "|2715824|           2011|Thrasher, Travis,...|        Oasis Audio,|    accd|        cabocd|         cen|        1|2019-02-01|\n",
      "|3331687|           2017|                null|          Kingswell,|    acbk|          nanf|         gwd|        1|2019-02-01|\n",
      "| 300513|           1915|Potter, Elizabeth...|P. Elder and Comp...|    arbk|          cs8r|         cen|        1|2019-02-01|\n",
      "|3356843|           2018|     Paschkis, Julie|Peachtree Publish...|    jcbk|         ncpic|         lcy|        1|2019-02-01|\n",
      "|3018542|           2014| Dowden, Joe Francis|Search Press Limi...|    acbk|          nanf|         nga|        1|2019-02-01|\n",
      "|2883246|           2009|        Glass, Cathy|     Harper Element,|    acbk|          nanf|         nga|        1|2019-02-01|\n",
      "|3183263|           2016|       Zommer, Yuval|    Thames & Hudson,|    jcbk|          ccnf|         cen|        2|2019-02-01|\n",
      "| 727948|           1969|   Aragon, 1897-1982|         [A. Skira],|    acbk|          caln|         cen|        1|2019-02-01|\n",
      "|3146621|           2015|      Logic (Rapper)| Def Jam Recordings,|    accd|          cacd|         cen|        1|2019-02-01|\n",
      "|1823223|           null|United States. Bu...|Office of Indian ...|    acbk|          canf|         cen|        1|2019-02-01|\n",
      "|3346837|           2007|Warner, Gertrude ...|Albert Whitman & ...|    jcbk|          ncef|         wts|        1|2019-02-01|\n",
      "| 449655|           null|                null|Gavin-Jobson Asso...|    arbk|          cs6r|         cen|        2|2019-02-01|\n",
      "|2927414|           2013|   Skármeta, Antonio|        Other Press,|    acbk|         cafic|         cen|        1|2019-02-01|\n",
      "|3359832|           2018|        Karbo, Karen|National Geographic;|    acbk|         nanew|         mon|        1|2019-02-01|\n",
      "|3337153|           2018|                null|                BBC,|   acdvd|         nadvd|         glk|        1|2019-02-01|\n",
      "|3359236|           2006|Le Guin, Ursula K...|      Orchard Books,|    jcbk|          ncef|         lcy|        1|2019-02-01|\n",
      "|2558025|           2009|        Noël, Alyson|St. Martin's Grif...|    acbk|         nyfic|         lcy|        1|2019-02-01|\n",
      "+-------+---------------+--------------------+--------------------+--------+--------------+------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+----------------+\n",
      "|BibNumber|CheckoutDateTime|\n",
      "+---------+----------------+\n",
      "|  2708128|      2015-08-22|\n",
      "|  2508714|      2014-05-17|\n",
      "|  3112108|      2015-11-14|\n",
      "|  2214553|      2014-01-30|\n",
      "|  2871391|      2014-08-04|\n",
      "|  3091044|      2015-11-22|\n",
      "|  2720198|      2015-05-14|\n",
      "|  2728686|      2015-11-30|\n",
      "|  2670960|      2014-08-27|\n",
      "|  3019542|      2015-02-11|\n",
      "|  2504824|      2014-09-02|\n",
      "|  2394314|      2014-06-27|\n",
      "|  3064512|      2015-12-20|\n",
      "|  2625862|      2014-07-08|\n",
      "|  2927972|      2014-11-26|\n",
      "|  2908009|      2014-04-30|\n",
      "|  2930199|      2014-03-05|\n",
      "|  2859932|      2014-06-04|\n",
      "|  2333548|      2014-03-06|\n",
      "|  1593555|      2014-01-25|\n",
      "+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inventory_df.show()\n",
    "checkout_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the tables to .parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:18.373973Z",
     "start_time": "2020-01-16T05:52:18.371724Z"
    }
   },
   "outputs": [],
   "source": [
    "# inventory_df.write.parquet('Inventory')\n",
    "# checkout_df.write.parquet('Checkouts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the parquet files and verify they worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:52:18.383290Z",
     "start_time": "2020-01-16T05:52:18.376074Z"
    }
   },
   "outputs": [],
   "source": [
    "# sqlContext = SQLContext(sc)\n",
    "# inventory_df = sqlContext.read.parquet('Inventory')\n",
    "# checkout_df = sqlContext.read.parquet('checkout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-16T05:53:54.713551Z",
     "start_time": "2020-01-16T05:53:54.711390Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! aws s3 cp Inventory s3://intersession-distcomp/Inventory --recursive\n",
    "# ! aws s3 cp Checkouts s3://intersession-distcomp/Checkouts --recursive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
